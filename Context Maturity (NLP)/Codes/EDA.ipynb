{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exploratory Data Analysis\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules and data\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "import datetime as dt \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "plt.rcParams['font.size'] = 15\n",
    "width = 0.75\n",
    "from wordcloud import WordCloud\n",
    "sns.set_palette(sns.color_palette('tab20', 20))\n",
    "import plotly.graph_objs as go\n",
    "from datetime import date, timedelta\n",
    "from empath import Empath\n",
    "lexicon = Empath()\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import iplot\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import cufflinks\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "\n",
    "data = pd.read_csv('/Users/qab/Desktop/Personal/NLP Projects/Context Maturity (NLP)/Data/jon_bellion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "source": [
    "## Drawing Empath Themes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the empath themes in the lyrics\n",
    "def extract_empath(lyrics):\n",
    "    return lexicon.analyze(lyrics)\n",
    "\n",
    "#Creates tags with the empath themes based on score\n",
    "def make_tags(tags):\n",
    "    tgs = [k for k, v in tags.items() if v != 0] #Helps set limit on tags to be kept\n",
    "    #tgs = sorted(tags.items(), key = lambda x: x[1], reverse = True)\n",
    "    return tgs\n",
    "\n",
    "#Processes the dictionary of tags and keeps the keys\n",
    "def process(st):\n",
    "    st = str(st)\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    new_s = st.translate(table)\n",
    "    return new_s\n",
    "\n",
    "data['empath_themes'] = data['lyrics'].apply(extract_empath).apply(make_tags).apply(process).apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of songs per album\n",
    "data.groupby('album').count()['titles'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Number of songs', \n",
    "    linecolor='black', \n",
    "    opacity=0,\n",
    "    title='Bar chart of songs per album release', \n",
    "    xTitle='Albums'\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Word count of lyrics before and after text preprocessing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count\n",
    "word_count = lambda x: len(str(x).split())\n",
    "data['song_length'] = data['lyrics'].astype(str).apply(len)\n",
    "data['lyrics_word_count'] = data['lyrics'].apply(word_count)\n",
    "data['processed_lyrics_word_count'] = data['processed_lyrics'].apply(word_count)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of all songs per album for unprocessed lyrics\n",
    "sns.set(rc = {'figure.figsize':(15, 10)})\n",
    "album1 = data[data['album'] == 'translation_through_speakers']['lyrics'].str.len()\n",
    "sns.distplot(album1, label = 'Translation Through Speakers')\n",
    "album2 = data[data['album'] == 'the_separation']['lyrics'].str.len()\n",
    "sns.distplot(album2, label = 'The Separation')\n",
    "album3 = data[data['album'] == 'the_definition']['lyrics'].str.len()\n",
    "sns.distplot(album3, label = 'The Definition')\n",
    "album4 = data[data['album'] == 'the_human_condition']['lyrics'].str.len()\n",
    "sns.distplot(album4, label = 'The Human Condition')\n",
    "album5 = data[data['album'] == 'glory_sound_prep']['lyrics'].str.len()\n",
    "sns.distplot(album5, label = 'Glory Sound Prep')\n",
    "plt.title('Length of lyrics per album released (Lyrics Not Processed)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of all songs per album for processed lyrics\n",
    "sns.set(rc = {'figure.figsize':(15, 10)})\n",
    "album1 = data[data['album'] == 'translation_through_speakers']['processed_lyrics'].str.len()\n",
    "sns.distplot(album1, label = 'Translation Through Speakers')\n",
    "album2 = data[data['album'] == 'the_separation']['processed_lyrics'].str.len()\n",
    "sns.distplot(album2, label = 'The Separation')\n",
    "album3 = data[data['album'] == 'the_definition']['processed_lyrics'].str.len()\n",
    "sns.distplot(album3, label = 'The Definition')\n",
    "album4 = data[data['album'] == 'the_human_condition']['processed_lyrics'].str.len()\n",
    "sns.distplot(album4, label = 'The Human Condition')\n",
    "album5 = data[data['album'] == 'glory_sound_prep']['processed_lyrics'].str.len()\n",
    "sns.distplot(album5, label = 'Glory Sound Prep')\n",
    "plt.title('Length of lyrics per album released (Pre-Processed Lyrics)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of songs and their length\n",
    "data['song_length'].iplot(\n",
    "    kind = 'hist',\n",
    "    bins = 56, #A small database so I limited this to the number of rows so the spread will be even. \n",
    "    xTitle = 'Song Length',\n",
    "    linecolor = 'black',\n",
    "    yTitle = 'Number of Songs',\n",
    "    title = 'Song Length Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count of lyrics before and after cleaning\n",
    "data[['lyrics_word_count', 'processed_lyrics_word_count']].iplot(\n",
    "    kind = 'hist',\n",
    "    bins = 20, #A small database so I limited this to the number of rows so the spread will be even. \n",
    "    xTitle = 'Word Count',\n",
    "    linecolor = 'black',\n",
    "    yTitle = 'Number of Songs',\n",
    "    title = 'Lyrics Count Per Song Distribution Before and After Pre-processing')"
   ]
  },
  {
   "source": [
    "## Sentiment and Subjectivity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting polarity and subjectivity with Textblob\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "#Creating new features for polarity and subjectivity\n",
    "data['polarity'] = data['lyrics'].apply(pol)\n",
    "data['subjectivity'] = data['lyrics'].apply(sub)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "source": [
    "## Visualising the sentiment and subectivity of songs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment polarity distribution - shows polarity range and number of songs in that range\n",
    "data['polarity'].iplot(\n",
    "    kind = 'hist',\n",
    "    bins = 56, #A small database so I limited this to the number of rows so the spread will be even. \n",
    "    xTitle = 'Lyrics Polarity',\n",
    "    linecolor = 'black',\n",
    "    yTitle = 'Number of Songs',\n",
    "    title = 'Sentiment Polarity Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity distribution - shows subjectivity range and number of songs in that range\n",
    "data['subjectivity'].iplot(\n",
    "    kind = 'hist',\n",
    "    bins = 56, #A small database so I limited this to the number of rows so the spread will be even. \n",
    "    xTitle = 'Lyrics Subjectivity',\n",
    "    linecolor = 'black',\n",
    "    yTitle = 'Number of Songs',\n",
    "    title = 'Subjectivity Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 2D density jointplot comparing sentiment and the length of the songs\n",
    "trace1 = go.Scatter(\n",
    "    x=data['polarity'], y=data['song_length'], mode='markers', name='points',\n",
    "    marker=dict(color='rgb(102,0,0)', size=2, opacity=0.4)\n",
    ")\n",
    "trace2 = go.Histogram2dContour(\n",
    "    x=data['polarity'], y=data['song_length'], name='density', ncontours=20,\n",
    "    colorscale='Hot', reversescale=True, showscale=False\n",
    ")\n",
    "trace3 = go.Histogram(\n",
    "    x=data['polarity'], name='Sentiment polarity density',\n",
    "    marker=dict(color='rgb(102,0,0)'),\n",
    "    yaxis='y2'\n",
    ")\n",
    "trace4 = go.Histogram(\n",
    "    y=data['song_length'], name='Song Length density', marker=dict(color='rgb(102,0,0)'),\n",
    "    xaxis='x2'\n",
    ")\n",
    "plot_data = [trace1, trace2, trace3, trace4]\n",
    "\n",
    "layout = go.Layout(\n",
    "    showlegend=False,\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=550,\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.85],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.85],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    margin=dict(\n",
    "        t=50\n",
    "    ),\n",
    "    hovermode='closest',\n",
    "    bargap=0,\n",
    "    xaxis2=dict(\n",
    "        domain=[0.85, 1],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0.85, 1],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=plot_data, layout=layout)\n",
    "iplot(fig, filename='2dhistogram-2d-density-plot-subplots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 2D density jointplot comparing subjectivity and the length of the songs\n",
    "trace1 = go.Scatter(\n",
    "    x=data['polarity'], y=data['subjectivity'], mode='markers', name='points',\n",
    "    marker=dict(color='rgb(102,0,0)', size=2, opacity=0.4)\n",
    ")\n",
    "trace2 = go.Histogram2dContour(\n",
    "    x=data['polarity'], y=data['subjectivity'], name='density', ncontours=20,\n",
    "    colorscale='Hot', reversescale=True, showscale=False\n",
    ")\n",
    "trace3 = go.Histogram(\n",
    "    x=data['polarity'], name='Sentiment polarity density',\n",
    "    marker=dict(color='rgb(102,0,0)'),\n",
    "    yaxis='y2'\n",
    ")\n",
    "trace4 = go.Histogram(\n",
    "    y=data['subjectivity'], name='Subjectivity density', marker=dict(color='rgb(102,0,0)'),\n",
    "    xaxis='x2'\n",
    ")\n",
    "plot_data = [trace1, trace2, trace3, trace4]\n",
    "\n",
    "layout = go.Layout(\n",
    "    showlegend=False,\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=550,\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.85],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.85],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    margin=dict(\n",
    "        t=50\n",
    "    ),\n",
    "    hovermode='closest',\n",
    "    bargap=0,\n",
    "    xaxis2=dict(\n",
    "        domain=[0.85, 1],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0.85, 1],\n",
    "        showgrid=False,\n",
    "        zeroline=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=plot_data, layout=layout)\n",
    "iplot(fig, filename='2dhistogram-2d-density-plot-subplots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising polarity against subjectivity\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "for index, title in enumerate(data.index):\n",
    "    x = data.polarity.loc[title]\n",
    "    y = data.subjectivity.loc[title]\n",
    "    plt.scatter(x, y, color='blue')\n",
    "    plt.text(x+.005, y+.005, data['titles'][index], fontsize=10)\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "plt.title('Sentiment and Subjectivity Plot', fontsize=25)\n",
    "plt.xlabel('<-- Negative -------- Positive -->', fontsize=15)\n",
    "plt.ylabel('<-- Facts -------- Opinions -->', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Drill down analysis of sentiment throughout the progression of the song"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to split lyrics into 'n' number of chunks\n",
    "def split_text(text, n = 5):\n",
    "    '''Takes in a string of text(lyrics) and splits into n equal parts, with a default of 10 equal parts.'''\n",
    "    \n",
    "    # Calculate length of text, the size of each chunk of text and the starting points of each chunk of text\n",
    "    length = len(text)\n",
    "    size = math.floor(length / n)\n",
    "    start = np.arange(0, length, size)\n",
    "    \n",
    "    # Pull out equally sized pieces of text and put it into a list\n",
    "    split_list = []\n",
    "    for piece in range(n):\n",
    "        split_list.append(text[start[piece]:start[piece]+size])\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying it out\n",
    "list_pieces = []\n",
    "for t in data.processed_lyrics:\n",
    "    split = split_text(t)\n",
    "    list_pieces.append(split)\n",
    "    \n",
    "#list_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the polarity for the pieces of lyric chunks\n",
    "polarity_lyrics = []\n",
    "for lp in list_pieces:\n",
    "    polarity_piece = []\n",
    "    for p in lp:\n",
    "        polarity_piece.append(TextBlob(p).sentiment.polarity)\n",
    "    polarity_lyrics.append(polarity_piece)\n",
    "    \n",
    "#polarity_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting sentment changes for the chunck of texts (lyrics)\n",
    "plt.plot(polarity_lyrics[1])\n",
    "plt.title(data['titles'].index[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for all songs\n",
    "plt.rcParams['figure.figsize'] = [50, 40]\n",
    "\n",
    "for index, title in enumerate(data.index):    \n",
    "    plt.subplot(8, 7, index+1)\n",
    "    plt.plot(polarity_lyrics[index])\n",
    "    plt.plot(np.arange(0, 5), np.zeros(5))\n",
    "    plt.title(data['titles'][index], fontsize = 18)\n",
    "    plt.ylim(ymin=-1, ymax=1)\n",
    "    plt.xlim(xmin=0, xmax=4)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Getting top words\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis = 0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(data['processed_lyrics'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "df1 = pd.DataFrame(common_words, columns = ['processed_lyrics' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the top words and their frequency\n",
    "df1.groupby('processed_lyrics').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar',\n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    title='Top 20 words in lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting top number of bi-gramns\n",
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_bigram(data['processed_lyrics'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "    \n",
    "df3 = pd.DataFrame(common_words, columns = ['processed_lyrics' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting bi-grams frequency\n",
    "df3.groupby('processed_lyrics').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    title='Top 20 bigrams in lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A boxplot showcasing the sentiment range for the albums\n",
    "y0 = data.loc[data['album'] == 'translation_through_speakers']['polarity']\n",
    "y1 = data.loc[data['album'] == 'the_separation']['polarity']\n",
    "y2 = data.loc[data['album'] == 'the_definition']['polarity']\n",
    "y3 = data.loc[data['album'] == 'the_human_condition']['polarity']\n",
    "y4 = data.loc[data['album'] == 'glory_sound_prep']['polarity']\n",
    "\n",
    "trace0 = go.Box(\n",
    "    y = y0,\n",
    "    name = 'Translation Through Speakers',\n",
    "    marker = dict(\n",
    "        color = 'rgb(214, 12, 140)',\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Box(\n",
    "    y = y1,\n",
    "    name = 'The Separation',\n",
    "    marker = dict(\n",
    "        color = 'rgb(0, 128, 128)',\n",
    "    )\n",
    ")\n",
    "\n",
    "trace2 = go.Box(\n",
    "    y = y2,\n",
    "    name = 'The Definition',\n",
    "    marker = dict(\n",
    "        color = 'rgb(10, 140, 208)',\n",
    "    )\n",
    ")\n",
    "\n",
    "trace3 = go.Box(\n",
    "    y = y3,\n",
    "    name = 'The Human Condition',\n",
    "    marker = dict(\n",
    "        color = 'rgb(12, 102, 14)',\n",
    "    )\n",
    ")\n",
    "\n",
    "trace4 = go.Box(\n",
    "    y = y4,\n",
    "    name = 'Glory Sound Prep',\n",
    "    marker = dict(\n",
    "        color = 'rgb(100, 0, 10)',\n",
    "    )\n",
    ")\n",
    "\n",
    "box_data = [trace0, trace1, trace2, trace3, trace4]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Sentiment Polarity Box Plot for Jon Bellion Albums'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = box_data, layout = layout)\n",
    "iplot(fig, filename = 'Sentiment Polarity Box Plot for Jon Bellion Albums')"
   ]
  }
 ]
}