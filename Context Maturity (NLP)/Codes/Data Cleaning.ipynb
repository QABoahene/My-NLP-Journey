{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Loading Data and Preparing Texts for Cleaning\n",
    "--- \n",
    "This is a sample text cleaning code, I was trying my hands on a couple of things so you will a lot of code lines which can be simplified. I will upload it when it is done. However this code should work perfectly for this project."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importinig modules\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import textblob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "#Loading data\n",
    "directory_path = '/Users/qab/Desktop/Personal/NLP Projects/Context Maturity (NLP)/Data'\n",
    "tts_music_files = os.listdir(directory_path + '/translation through speakers')\n",
    "ts_music_files = os.listdir(directory_path + '/the separation')\n",
    "td_music_files = os.listdir(directory_path + '/the definition')\n",
    "thc_music_files = os.listdir(directory_path + '/the human condition')\n",
    "gsp_music_files = os.listdir(directory_path + '/glory sound prep')\n",
    "\n",
    "tts = []\n",
    "ts = []\n",
    "td = []\n",
    "thc = []\n",
    "gsp = []\n",
    "\n",
    "for i, music in enumerate(tts_music_files):\n",
    "    with open(directory_path + '/translation through speakers/' + music, 'rt') as file:\n",
    "        tts.append(file.read())\n",
    "\n",
    "for i, music in enumerate(ts_music_files):\n",
    "    with open(directory_path + '/the separation/' + music, 'rt') as file:\n",
    "        ts.append(file.read())\n",
    "\n",
    "for i, music in enumerate(td_music_files):\n",
    "    with open(directory_path + '/the definition/' + music, 'rt') as file:\n",
    "        td.append(file.read())\n",
    "\n",
    "for i, music in enumerate(thc_music_files):\n",
    "    with open(directory_path + '/the human condition/' + music, 'rt') as file:\n",
    "        thc.append(file.read())\n",
    "\n",
    "for i, music in enumerate(gsp_music_files):\n",
    "    with open(directory_path + '/glory sound prep/' + music, 'rt') as file:\n",
    "        gsp.append(file.read())\n",
    "\n",
    "tts_dictionary = dict(zip(tts_music_files, tts))\n",
    "ts_dictionary = dict(zip(ts_music_files, ts))\n",
    "td_dictionary = dict(zip(td_music_files, td))\n",
    "thc_dictionary = dict(zip(thc_music_files, thc))\n",
    "gsp_dictionary = dict(zip(gsp_music_files, gsp)) \n",
    "\n",
    "#Combining list of texts and putting it into a pandas dataframe\n",
    "def lyrics_together(lyrics_list):\n",
    "    #Takes a list of text and combines them into one large chunk of text.\n",
    "    lyrics_together = ''.join(lyrics_list)\n",
    "    return lyrics_together\n",
    "\n",
    "tts_combined = {key: [lyrics_together(value)] for (key, value) in tts_dictionary.items()}\n",
    "ts_combined = {key: [lyrics_together(value)] for (key, value) in ts_dictionary.items()}\n",
    "td_combined = {key: [lyrics_together(value)] for (key, value) in td_dictionary.items()}\n",
    "thc_combined = {key: [lyrics_together(value)] for (key, value) in thc_dictionary.items()}\n",
    "gsp_combined = {key: [lyrics_together(value)] for (key, value) in gsp_dictionary.items()}\n",
    "\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "tts = pd.DataFrame.from_dict(tts_combined).transpose()\n",
    "tts.columns = ['lyrics']\n",
    "tts = tts.sort_index()\n",
    "tts = pd.DataFrame.reset_index(tts, drop = False)\n",
    "tts.rename(columns = {'index':'titles'}, inplace = True)\n",
    "\n",
    "ts = pd.DataFrame.from_dict(ts_combined).transpose()\n",
    "ts.columns = ['lyrics']\n",
    "ts = ts.sort_index()\n",
    "ts = pd.DataFrame.reset_index(ts, drop = False)\n",
    "ts.rename(columns = {'index':'titles'}, inplace = True)\n",
    "\n",
    "td = pd.DataFrame.from_dict(td_combined).transpose()\n",
    "td.columns = ['lyrics']\n",
    "td = td.sort_index()\n",
    "td = pd.DataFrame.reset_index(td, drop = False)\n",
    "td.rename(columns = {'index':'titles'}, inplace = True)\n",
    "\n",
    "thc = pd.DataFrame.from_dict(thc_combined).transpose()\n",
    "thc.columns = ['lyrics']\n",
    "thc = thc.sort_index()\n",
    "thc = pd.DataFrame.reset_index(thc, drop = False)\n",
    "thc.rename(columns = {'index':'titles'}, inplace = True)\n",
    "\n",
    "gsp = pd.DataFrame.from_dict(gsp_combined).transpose()\n",
    "gsp.columns = ['lyrics']\n",
    "gsp = gsp.sort_index()\n",
    "gsp = pd.DataFrame.reset_index(gsp, drop = False)\n",
    "gsp.rename(columns = {'index':'titles'}, inplace = True)\n",
    "\n",
    "#Defining a function for initial text cleaning\n",
    "stop_words = stopwords.words(\"english\")\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "translation_through_speakers = pd.DataFrame(tts.lyrics)\n",
    "the_separation = pd.DataFrame(ts.lyrics)\n",
    "the_definition = pd.DataFrame(td.lyrics) \n",
    "the_human_condition = pd.DataFrame(thc.lyrics)\n",
    "glory_sound_prep = pd.DataFrame(gsp.lyrics)\n",
    "\n",
    "tts_titles = ['dead man wallking', 'dont ask cuz i dont know', 'for the dreamers', 'life', 'paper planes', 'the wonder years', 'timeless', 'waves of loneliness', 'while you count sheep', 'wutup snow']\n",
    "\n",
    "ts_titles = ['2 rocking chairs', 'eyes to the sky', 'halloween', 'jim morrison', 'kingdom come', 'newyorksoul', 'one more time', 'superman, the gift and the curse', 'to my future wife...', 'ungrateful eyes', 'when the lions come']\n",
    "\n",
    "td_titles = ['a haunted house', 'an immigrant', 'carry your throne', 'human', 'jungle', 'luxury', 'munny right', 'ooh', 'pre-occupied', 'run wild', 'simple and sweet']\n",
    "\n",
    "thc_titles = [\"80's films\", \"all time low\", \"fashion\", \"guillotine\", \"hand of god (outro)\", \"he is the same\", \"irobot\", \"maybe idk\", \"morning in america\", \"new york soul (part ii)\", \"overwhelming\", \"the good in me\", \"weight of the world\", \"woke the fuck up\"]\n",
    "\n",
    "gsp_titles = ['adult swim', 'blu', 'cautionary tales', 'conversations with my wife', 'couples retreat', 'jt', \"let's begin\", \"mah's joint\", 'stupid deep', 'the internet']\n",
    "\n",
    "translation_through_speakers['titles'] = tts_titles\n",
    "the_definition['titles'] = td_titles\n",
    "the_separation['titles'] = ts_titles\n",
    "the_human_condition['titles'] = thc_titles\n",
    "glory_sound_prep['titles'] = gsp_titles\n",
    "\n",
    "translation_through_speakers['date_released'] = 'February 20, 2013'\n",
    "the_separation['date_released'] = 'December 10, 2013'\n",
    "the_definition['date_released'] = 'September 23, 2014'\n",
    "the_human_condition['date_released'] = 'June 20, 2016'\n",
    "glory_sound_prep['date_released'] = 'November 9, 2018'\n",
    "\n",
    "translation_through_speakers['album'] = 'translation_through_speakers'\n",
    "the_separation['album'] = 'the_separation'\n",
    "the_definition['album'] = 'the_definition'\n",
    "the_human_condition['album'] = 'the_human_condition'\n",
    "glory_sound_prep['album'] = 'glory_sound_prep'\n",
    "\n",
    "jon_bellion = pd.concat([translation_through_speakers, the_separation, the_definition, the_human_condition, glory_sound_prep], axis=0)\n",
    "jon_bellion = pd.DataFrame.reset_index(jon_bellion, drop = True)\n",
    "\n",
    "def initial_clean(lyrics):\n",
    "    lyrics = re.sub('\\[.*?\\]', '', lyrics)\n",
    "    lyrics = lyrics.lower()\n",
    "    lyrics = ' '.join(wordnet.lemmatize(word, 'v') for word  in lyrics.split())\n",
    "    lyrics = re.sub('[%s]' % re.escape(string.punctuation), '', lyrics)\n",
    "    lyrics = ' '.join([word for word in lyrics.split(' ') if word not in stop_words])\n",
    "    lyrics = re.sub('\\n', ' ', lyrics)\n",
    "    lyrics = re.sub('[''\"\"’—...]', '', lyrics)\n",
    "    lyrics = re.sub('\\w*\\d\\w*', '', lyrics)\n",
    "    return lyrics\n",
    "cleaning = lambda song: initial_clean(song)\n",
    "\n",
    "jon_bellion['processed_lyrics'] = jon_bellion['lyrics'].apply(initial_clean)\n",
    "\n",
    "not_needed = ['yeah', 'bum', 'la', 'da', 'ba', 'oh', 'ohh', 'ooh', 'mama', 'nana', 'yah', 'uh', 'ew', 'dum', 'ho', 'ya', 'nay', 'nan', 'yo', 'nanana', 'uhuh', 'badem', 'buhda', 'dadada', 'dadum']\n",
    "words_to_remove = r'\\b(?:{})\\b'.format('|'.join(not_needed))\n",
    "\n",
    "jon_bellion['processed_lyrics'] = jon_bellion['processed_lyrics'].str.replace(words_to_remove, '')\n",
    "\n",
    "jon_bellion = jon_bellion[['titles', 'album', 'date_released', 'lyrics', 'processed_lyrics']]\n",
    "\n",
    "#jon_bellion.to_csv(directory_path + '/' + 'jon_bellion.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}