{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac94c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers==4.12.5 pandas torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a5ddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on transformers v4.12.5\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(f\"Running on transformers v{transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b496e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          PreTrainedModel, DistilBertModel, DistilBertForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee355cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9837ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76b0157df2f40dbbfc6ac052e2bc677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe510df7f6049e6bfc9d5bedd2d75a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset go_emotions/raw (download: 40.76 MiB, generated: 52.78 MiB, post-processed: Unknown size, total: 93.54 MiB) to C:\\Users\\aquarshie\\.cache\\huggingface\\datasets\\go_emotions\\raw\\0.0.0\\2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c9b3545c4d424b9ade26a8d29a619c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8701755ee0cf4209b7e85439735c5c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5433095b708341d6b93add1ef9ca2291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2682178062904988a957cf4a0a2c1c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4005269b343241e18c355af21ba18e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/211225 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset go_emotions downloaded and prepared to C:\\Users\\aquarshie\\.cache\\huggingface\\datasets\\go_emotions\\raw\\0.0.0\\2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beec83ad61cf48bd8e8130b945ed63b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "emotions = load_dataset(\"go_emotions\", \"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d086b410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'],\n",
       "        num_rows: 211225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdeef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = emotions['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b77a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
    "len(label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d06b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {str(i):label for i, label in enumerate(label_cols)}\n",
    "label2id = {label:str(i) for i, label in enumerate(label_cols)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a98e387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'admiration',\n",
       " '1': 'amusement',\n",
       " '2': 'anger',\n",
       " '3': 'annoyance',\n",
       " '4': 'approval',\n",
       " '5': 'caring',\n",
       " '6': 'confusion',\n",
       " '7': 'curiosity',\n",
       " '8': 'desire',\n",
       " '9': 'disappointment',\n",
       " '10': 'disapproval',\n",
       " '11': 'disgust',\n",
       " '12': 'embarrassment',\n",
       " '13': 'excitement',\n",
       " '14': 'fear',\n",
       " '15': 'gratitude',\n",
       " '16': 'grief',\n",
       " '17': 'joy',\n",
       " '18': 'love',\n",
       " '19': 'nervousness',\n",
       " '20': 'optimism',\n",
       " '21': 'pride',\n",
       " '22': 'realization',\n",
       " '23': 'relief',\n",
       " '24': 'remorse',\n",
       " '25': 'sadness',\n",
       " '26': 'surprise',\n",
       " '27': 'neutral'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c785a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiration': '0',\n",
       " 'amusement': '1',\n",
       " 'anger': '2',\n",
       " 'annoyance': '3',\n",
       " 'approval': '4',\n",
       " 'caring': '5',\n",
       " 'confusion': '6',\n",
       " 'curiosity': '7',\n",
       " 'desire': '8',\n",
       " 'disappointment': '9',\n",
       " 'disapproval': '10',\n",
       " 'disgust': '11',\n",
       " 'embarrassment': '12',\n",
       " 'excitement': '13',\n",
       " 'fear': '14',\n",
       " 'gratitude': '15',\n",
       " 'grief': '16',\n",
       " 'joy': '17',\n",
       " 'love': '18',\n",
       " 'nervousness': '19',\n",
       " 'optimism': '20',\n",
       " 'pride': '21',\n",
       " 'realization': '22',\n",
       " 'relief': '23',\n",
       " 'remorse': '24',\n",
       " 'sadness': '25',\n",
       " 'surprise': '26',\n",
       " 'neutral': '27'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61c37b",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a235be60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                 Man I love reddit.  eeibobj   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1          TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "\n",
       "    created_utc  rater_id  example_very_unclear  admiration  ...  nervousness  \\\n",
       "0  1.548381e+09         1                 False           0  ...            0   \n",
       "1  1.548084e+09        37                 False           0  ...            0   \n",
       "2  1.546428e+09        37                 False           0  ...            0   \n",
       "3  1.547965e+09        18                 False           0  ...            0   \n",
       "4  1.546669e+09         2                 False           0  ...            0   \n",
       "\n",
       "   optimism  pride  realization  relief  remorse  sadness  surprise  neutral  \\\n",
       "0         0      0            0       0        0        1         0        0   \n",
       "1         0      0            0       0        0        0         0        0   \n",
       "2         0      0            0       0        0        0         0        1   \n",
       "3         0      0            0       0        0        0         0        0   \n",
       "4         0      0            0       0        0        0         0        1   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"] = df[label_cols].values.tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e0964cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take sample for quick prototyping\n",
    "df_sample = df.sample(n=1000)\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45cbaa86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((168693, 38), (42532, 38))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train / test splits\n",
    "mask = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[mask]\n",
    "df_test = df[~mask]\n",
    "\n",
    "(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c0de9",
   "metadata": {},
   "source": [
    "## Tokenize and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bddf54da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb05a735f6545b2890949c0dd38253f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600f5e7540a04977bff16ea895db723c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3854674747646d6aba87cd295373e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2604a45abe1a44f583239fd65d313b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fd8bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(df_train[\"text\"].values.tolist(), truncation=True)\n",
    "test_encodings = tokenizer(df_test[\"text\"].values.tolist(), truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5af9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df_train[\"labels\"].values.tolist()\n",
    "test_labels = df_test[\"labels\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e31e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoEmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "612f7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GoEmotionDataset(train_encodings, train_labels)\n",
    "test_dataset = GoEmotionDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c50d560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1028, 13798,  5807,  1521,  1056,  2022,  1037, 19765,  4696,\n",
       "          2009,  3084,  2017,  2367,  2013, 27178, 27065,  4903,  2140,  2061,\n",
       "         10047,  2080,  2009, 16142,  1996,  6210,  1997,  1000, 19765,  1000,\n",
       "           102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20d2f0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] > sexuality shouldn ’ t be a grouping category it makes you different from othet ppl so imo it fits the definition of \" grouping \" [SEP]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "tokenizer.decode(train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a7d7a",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "There are two ways we can implement multi-label classification:\n",
    "\n",
    "- Creating a custom BERT model that overrides the forward method\n",
    "- Creating a custom Trainer that overrides the compute_loss method\n",
    "The second method does not work with v4.2.1 of transformers due to some bugs, so we'll work with the first approach instead :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f541d529",
   "metadata": {},
   "source": [
    "### Creating a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6443657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertForMultilabelSequenceClassification(DistilBertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "      super().__init__(config)\n",
    "\n",
    "    def forward(self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.distilbert(input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict)\n",
    "\n",
    "        hidden_state = outputs[0]\n",
    "        pooled_output = hidden_state[:, 0]  \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                            labels.float().view(-1, self.num_labels))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "143df35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForMultilabelSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForMultilabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMultilabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMultilabelSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels=28\n",
    "model = DistilBertForMultilabelSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels)#.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b22dad13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": [\n",
       "    {\n",
       "      \"0\": \"admiration\",\n",
       "      \"1\": \"amusement\",\n",
       "      \"10\": \"disapproval\",\n",
       "      \"11\": \"disgust\",\n",
       "      \"12\": \"embarrassment\",\n",
       "      \"13\": \"excitement\",\n",
       "      \"14\": \"fear\",\n",
       "      \"15\": \"gratitude\",\n",
       "      \"16\": \"grief\",\n",
       "      \"17\": \"joy\",\n",
       "      \"18\": \"love\",\n",
       "      \"19\": \"nervousness\",\n",
       "      \"2\": \"anger\",\n",
       "      \"20\": \"optimism\",\n",
       "      \"21\": \"pride\",\n",
       "      \"22\": \"realization\",\n",
       "      \"23\": \"relief\",\n",
       "      \"24\": \"remorse\",\n",
       "      \"25\": \"sadness\",\n",
       "      \"26\": \"surprise\",\n",
       "      \"27\": \"neutral\",\n",
       "      \"3\": \"annoyance\",\n",
       "      \"4\": \"approval\",\n",
       "      \"5\": \"caring\",\n",
       "      \"6\": \"confusion\",\n",
       "      \"7\": \"curiosity\",\n",
       "      \"8\": \"desire\",\n",
       "      \"9\": \"disappointment\"\n",
       "    }\n",
       "  ],\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"admiration\": 0,\n",
       "    \"amusement\": 1,\n",
       "    \"anger\": 2,\n",
       "    \"annoyance\": 3,\n",
       "    \"approval\": 4,\n",
       "    \"caring\": 5,\n",
       "    \"confusion\": 6,\n",
       "    \"curiosity\": 7,\n",
       "    \"desire\": 8,\n",
       "    \"disappointment\": 9,\n",
       "    \"disapproval\": 10,\n",
       "    \"disgust\": 11,\n",
       "    \"embarrassment\": 12,\n",
       "    \"excitement\": 13,\n",
       "    \"fear\": 14,\n",
       "    \"gratitude\": 15,\n",
       "    \"grief\": 16,\n",
       "    \"joy\": 17,\n",
       "    \"love\": 18,\n",
       "    \"nervousness\": 19,\n",
       "    \"neutral\": 27,\n",
       "    \"optimism\": 20,\n",
       "    \"pride\": 21,\n",
       "    \"realization\": 22,\n",
       "    \"relief\": 23,\n",
       "    \"remorse\": 24,\n",
       "    \"sadness\": 25,\n",
       "    \"surprise\": 26\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.12.5\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label = {\n",
    "    \"0\": \"admiration\",\n",
    "    \"1\": \"amusement\",\n",
    "    \"2\": \"anger\",\n",
    "    \"3\": \"annoyance\",\n",
    "    \"4\": \"approval\",\n",
    "    \"5\": \"caring\",\n",
    "    \"6\": \"confusion\",\n",
    "    \"7\": \"curiosity\",\n",
    "    \"8\": \"desire\",\n",
    "    \"9\": \"disappointment\",\n",
    "    \"10\": \"disapproval\",\n",
    "    \"11\": \"disgust\",\n",
    "    \"12\": \"embarrassment\",\n",
    "    \"13\": \"excitement\",\n",
    "    \"14\": \"fear\",\n",
    "    \"15\": \"gratitude\",\n",
    "    \"16\": \"grief\",\n",
    "    \"17\": \"joy\",\n",
    "    \"18\": \"love\",\n",
    "    \"19\": \"nervousness\",\n",
    "    \"20\": \"optimism\",\n",
    "    \"21\": \"pride\",\n",
    "    \"22\": \"realization\",\n",
    "    \"23\": \"relief\",\n",
    "    \"24\": \"remorse\",\n",
    "    \"25\": \"sadness\",\n",
    "    \"26\": \"surprise\",\n",
    "    \"27\": \"neutral\"\n",
    "  },\n",
    "model.config.label2id ={\n",
    "    \"admiration\": 0,\n",
    "    \"amusement\": 1,\n",
    "    \"anger\": 2,\n",
    "    \"annoyance\": 3,\n",
    "    \"approval\": 4,\n",
    "    \"caring\": 5,\n",
    "    \"confusion\": 6,\n",
    "    \"curiosity\": 7,\n",
    "    \"desire\": 8,\n",
    "    \"disappointment\": 9,\n",
    "    \"disapproval\": 10,\n",
    "    \"disgust\": 11,\n",
    "    \"embarrassment\": 12,\n",
    "    \"excitement\": 13,\n",
    "    \"fear\": 14,\n",
    "    \"gratitude\": 15,\n",
    "    \"grief\": 16,\n",
    "    \"joy\": 17,\n",
    "    \"love\": 18,\n",
    "    \"nervousness\": 19,\n",
    "    \"neutral\": 27,\n",
    "    \"optimism\": 20,\n",
    "    \"pride\": 21,\n",
    "    \"realization\": 22,\n",
    "    \"relief\": 23,\n",
    "    \"remorse\": 24,\n",
    "    \"sadness\": 25,\n",
    "    \"surprise\": 26\n",
    "  }\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47ac0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_thresh(y_pred, y_true, thresh=0.5, sigmoid=True): \n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    if sigmoid: \n",
    "      y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred>thresh)==y_true.bool()).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7433f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return {'accuracy_thresh': accuracy_thresh(predictions, labels)}\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f27c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# configure logging so we see training loss\n",
    "logging_steps = len(train_dataset) // batch_size\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"emotion\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=logging_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff7b5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71040b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42532\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1330' max='1330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1330/1330 18:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7321420311927795,\n",
       " 'eval_accuracy_thresh': 0.42745545506477356,\n",
       " 'eval_runtime': 1090.194,\n",
       " 'eval_samples_per_second': 39.013,\n",
       " 'eval_steps_per_second': 1.22}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that we can run evaluation\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bee2b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 168693\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='491' max='15816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  491/15816 20:40 < 10:47:55, 0.39 it/s, Epoch 0.09/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\nlp_transformers\\lib\\site-packages\\transformers\\trainer.py:1316\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1314\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1316\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1319\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1322\u001b[0m ):\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\nlp_transformers\\lib\\site-packages\\transformers\\trainer.py:1867\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1865\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1867\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\nlp_transformers\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\nlp_transformers\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36af35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that we can run evaluation\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b8e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
